\begin{tabular}{llrrrrrrrrrrrrrrrrr}
\toprule
model & family & overall_mean & overall_sd & Q-1-Accuracy & Q-1-Completeness & Q-1-Detail & Q-2-Accuracy & Q-2-Completeness & Q-2-Detail & Q-3-Accuracy & Q-3-Completeness & Q-3-Detail & Q-4-Accuracy & Q-4-Completeness & Q-4-Detail & Q-5-Accuracy & Q-5-Completeness & Q-5-Detail \\
\midrule
gpt-4-1 & OpenAI & 8.35 & 3.40 & 9.83 & 5.73 & 9.90 & 9.73 & 5.65 & 9.85 & 9.84 & 5.68 & 9.75 & 9.90 & 5.19 & 9.59 & 9.71 & 5.08 & 9.80 \\
o4-mini & OpenAI & 8.35 & 3.40 & 9.84 & 5.68 & 9.91 & 9.69 & 5.65 & 9.87 & 9.76 & 5.61 & 9.82 & 9.87 & 5.27 & 9.79 & 9.53 & 5.24 & 9.70 \\
llama3-2 & Local & 8.27 & 3.43 & 9.84 & 5.50 & 9.81 & 9.65 & 5.38 & 9.81 & 9.88 & 5.30 & 9.82 & 9.88 & 5.31 & 9.33 & 9.60 & 5.23 & 9.75 \\
gpt-5-mini & OpenAI & 8.17 & 3.61 & 9.82 & 4.96 & 9.89 & 9.63 & 4.96 & 9.86 & 9.77 & 4.89 & 9.87 & 9.88 & 4.87 & 9.88 & 9.72 & 4.73 & 9.88 \\
gpt-5 & OpenAI & 8.14 & 3.62 & 9.79 & 4.93 & 9.89 & 9.61 & 4.96 & 9.84 & 9.78 & 4.90 & 9.89 & 9.88 & 4.64 & 9.81 & 9.73 & 4.69 & 9.83 \\
deepseek-r1 & Local & 8.13 & 3.46 & 9.63 & 5.68 & 9.75 & 9.57 & 5.46 & 9.82 & 9.34 & 5.50 & 9.38 & 9.36 & 5.49 & 8.48 & 9.76 & 4.87 & 9.80 \\
llama3 & Local & 8.10 & 3.52 & 9.54 & 5.70 & 9.59 & 9.46 & 5.61 & 9.55 & 9.62 & 5.50 & 9.45 & 9.49 & 5.51 & 8.78 & 9.37 & 4.90 & 9.44 \\
gpt-4o & OpenAI & 7.97 & 3.61 & 9.85 & 4.92 & 9.84 & 9.67 & 4.88 & 9.84 & 9.78 & 4.79 & 9.46 & 9.80 & 4.08 & 8.94 & 9.63 & 4.25 & 9.75 \\
\bottomrule
\end{tabular}
